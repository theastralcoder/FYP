{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7856557,"sourceType":"datasetVersion","datasetId":4608097},{"sourceId":7856788,"sourceType":"datasetVersion","datasetId":4608260},{"sourceId":7872939,"sourceType":"datasetVersion","datasetId":4619766},{"sourceId":7892649,"sourceType":"datasetVersion","datasetId":4634064},{"sourceId":12477,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":10324},{"sourceId":17503,"sourceType":"modelInstanceVersion","modelInstanceId":14566}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n\nimport numpy as np\nimport cv2\nfrom glob import glob\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import CustomObjectScope\nfrom sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score\n\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, Activation\nfrom tensorflow.keras.layers import MaxPool2D, Conv2DTranspose, Concatenate, Input\nfrom tensorflow.keras.models import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-21T13:34:46.176996Z","iopub.execute_input":"2024-03-21T13:34:46.177758Z","iopub.status.idle":"2024-03-21T13:34:59.096804Z","shell.execute_reply.started":"2024-03-21T13:34:46.177725Z","shell.execute_reply":"2024-03-21T13:34:59.095880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_block(inputs, num_filters):\n    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"relu\")(x)\n\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-03-21T13:34:59.098931Z","iopub.execute_input":"2024-03-21T13:34:59.099796Z","iopub.status.idle":"2024-03-21T13:34:59.107588Z","shell.execute_reply.started":"2024-03-21T13:34:59.099760Z","shell.execute_reply":"2024-03-21T13:34:59.106398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder_block(inputs, num_filters):\n    x = conv_block(inputs, num_filters)\n    p = MaxPool2D((2, 2))(x)\n    return x, p","metadata":{"execution":{"iopub.status.busy":"2024-03-21T13:34:59.109125Z","iopub.execute_input":"2024-03-21T13:34:59.110025Z","iopub.status.idle":"2024-03-21T13:34:59.137476Z","shell.execute_reply.started":"2024-03-21T13:34:59.109987Z","shell.execute_reply":"2024-03-21T13:34:59.136558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decoder_block(inputs, skip_features, num_filters):\n    x = Conv2DTranspose(num_filters, 2, strides=2, padding=\"same\")(inputs)\n    x = Concatenate()([x, skip_features])\n    x = conv_block(x, num_filters)\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-03-21T13:34:59.140008Z","iopub.execute_input":"2024-03-21T13:34:59.140990Z","iopub.status.idle":"2024-03-21T13:34:59.149965Z","shell.execute_reply.started":"2024-03-21T13:34:59.140951Z","shell.execute_reply":"2024-03-21T13:34:59.149028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def unet(input_shape):\n    inputs = Input(input_shape)\n\n    s1, p1 = encoder_block(inputs, 64)\n    s2, p2 = encoder_block(p1, 128)\n    s3, p3 = encoder_block(p2, 256)\n    s4, p4 = encoder_block(p3, 512)\n\n    b1 = conv_block(p4, 1024)\n\n    d1 = decoder_block(b1, s4, 512)\n    d2 = decoder_block(d1, s3, 256)\n    d3 = decoder_block(d2, s2, 128)\n    d4 = decoder_block(d3, s1, 64)\n\n    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n\n    model = Model(inputs, outputs, name=\"UNET\")\n    return model\n\nmodel = unet((224,224,3))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-21T13:34:59.151058Z","iopub.execute_input":"2024-03-21T13:34:59.151378Z","iopub.status.idle":"2024-03-21T13:35:00.261310Z","shell.execute_reply.started":"2024-03-21T13:34:59.151352Z","shell.execute_reply":"2024-03-21T13:35:00.260459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"smooth = 1e-15\ndef dice_coef(y_true, y_pred):\n    y_true = tf.keras.layers.Flatten()(y_true)\n    y_pred = tf.keras.layers.Flatten()(y_pred)\n    intersection = tf.reduce_sum(y_true * y_pred)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1.0 - dice_coef(y_true, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:48:44.047520Z","iopub.execute_input":"2024-03-20T06:48:44.047910Z","iopub.status.idle":"2024-03-20T06:48:44.054249Z","shell.execute_reply.started":"2024-03-20T06:48:44.047882Z","shell.execute_reply":"2024-03-20T06:48:44.053292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"H = 224\nW = 224\n\ndef create_dir(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\ncreate_dir(\"files\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:48:52.190240Z","iopub.execute_input":"2024-03-20T06:48:52.191084Z","iopub.status.idle":"2024-03-20T06:48:52.196013Z","shell.execute_reply.started":"2024-03-20T06:48:52.191048Z","shell.execute_reply":"2024-03-20T06:48:52.195078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dataset(path, split=0.2):\n    images = sorted(glob(os.path.join(path, \"*\", \"*.jpg\")))\n    masks = sorted(glob(os.path.join(path, \"HAM10000_segmentations_lesion_tschandl/HAM10000_segmentations_lesion_tschandl\", \"*.png\")))\n    print(len(images),len(masks))\n    split_size = int(len(images) * split)\n\n    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n \n    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n\n    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:48:46.647583Z","iopub.execute_input":"2024-03-20T06:48:46.647952Z","iopub.status.idle":"2024-03-20T06:48:46.655587Z","shell.execute_reply.started":"2024-03-20T06:48:46.647920Z","shell.execute_reply":"2024-03-20T06:48:46.654621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_image(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_COLOR)\n    x = cv2.resize(x, (W, H))\n    x = x / 255.0\n    x = x.astype(np.float32)\n    return x\n\ndef read_mask(path):\n    path = path.decode()\n    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (h, w)\n    x = cv2.resize(x, (W, H))   ## (h, w)\n    x = x / 255.0               ## (h, w)\n    x = x.astype(np.float32)    ## (h, w)\n    x = np.expand_dims(x, axis=-1)## (h, w, 1)\n    return x","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:07:51.264187Z","iopub.execute_input":"2024-03-16T09:07:51.264497Z","iopub.status.idle":"2024-03-16T09:07:51.274047Z","shell.execute_reply.started":"2024-03-16T09:07:51.264467Z","shell.execute_reply":"2024-03-16T09:07:51.273265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tf_parse(x, y):\n    def _parse(x, y):\n        x = read_image(x)\n        y = read_mask(y)\n        return x, y\n\n    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n    x.set_shape([H, W, 3])\n    y.set_shape([H, W, 1])\n    return x, y\n\ndef tf_dataset(X, Y, batch=2):\n    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n    dataset = dataset.map(tf_parse)\n    dataset = dataset.batch(batch)\n    dataset = dataset.prefetch(10)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:07:51.276662Z","iopub.execute_input":"2024-03-16T09:07:51.276929Z","iopub.status.idle":"2024-03-16T09:07:51.288298Z","shell.execute_reply.started":"2024-03-16T09:07:51.276907Z","shell.execute_reply":"2024-03-16T09:07:51.287363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nlr = 1e-4\nnum_epochs = 100\nmodel_path = os.path.join(\"files\", \"model.h5\")\ncsv_path = os.path.join(\"files\", \"log.csv\")\ndataset_path=\"/kaggle/input/seg-dataset\"","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:49:12.358232Z","iopub.execute_input":"2024-03-20T06:49:12.358966Z","iopub.status.idle":"2024-03-20T06:49:12.363757Z","shell.execute_reply.started":"2024-03-20T06:49:12.358926Z","shell.execute_reply":"2024-03-20T06:49:12.362760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n\nprint(f\"Train: ({len(train_x)},{len(train_y)})\")\nprint(f\"Valid: ({len(valid_x)},{len(valid_x)})\")\nprint(f\"Test: ({len(test_x)},{len(test_x)})\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:25:05.185123Z","iopub.execute_input":"2024-03-16T09:25:05.185433Z","iopub.status.idle":"2024-03-16T09:25:05.280939Z","shell.execute_reply.started":"2024-03-16T09:25:05.185410Z","shell.execute_reply":"2024-03-16T09:25:05.280051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\nvalid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:25:05.993370Z","iopub.execute_input":"2024-03-16T09:25:05.994005Z","iopub.status.idle":"2024-03-16T09:25:06.078735Z","shell.execute_reply.started":"2024-03-16T09:25:05.993973Z","shell.execute_reply":"2024-03-16T09:25:06.077945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = unet((H, W, 3))\nmodel.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef,'accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:49:23.698154Z","iopub.execute_input":"2024-03-20T06:49:23.698551Z","iopub.status.idle":"2024-03-20T06:49:24.031539Z","shell.execute_reply.started":"2024-03-20T06:49:23.698522Z","shell.execute_reply":"2024-03-20T06:49:24.030497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [\n        ModelCheckpoint(model_path+'.keras', verbose=1, save_best_only=True),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n        CSVLogger(csv_path),\n        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n    ]","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:25:06.966367Z","iopub.execute_input":"2024-03-16T09:25:06.966950Z","iopub.status.idle":"2024-03-16T09:25:06.971785Z","shell.execute_reply.started":"2024-03-16T09:25:06.966920Z","shell.execute_reply":"2024-03-16T09:25:06.970797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_dataset,epochs=num_epochs,validation_data=valid_dataset,callbacks=callbacks,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:25:07.657942Z","iopub.execute_input":"2024-03-16T09:25:07.658624Z","iopub.status.idle":"2024-03-16T09:28:40.902748Z","shell.execute_reply.started":"2024-03-16T09:25:07.658592Z","shell.execute_reply":"2024-03-16T09:28:40.901742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nmetrics = pd.read_csv(\"/kaggle/working/files/log.csv\")\nmetrics","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:28:47.353531Z","iopub.execute_input":"2024-03-16T09:28:47.354135Z","iopub.status.idle":"2024-03-16T09:28:47.377470Z","shell.execute_reply.started":"2024-03-16T09:28:47.354104Z","shell.execute_reply":"2024-03-16T09:28:47.376603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['dice_coef','val_dice_coef']].plot()\nplt.savefig('metrics_dice_plot.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['accuracy','val_accuracy']].plot()\nplt.savefig('metrics_accuracy_plot.png')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:28:50.430253Z","iopub.execute_input":"2024-03-16T09:28:50.431068Z","iopub.status.idle":"2024-03-16T09:28:50.664105Z","shell.execute_reply.started":"2024-03-16T09:28:50.431035Z","shell.execute_reply":"2024-03-16T09:28:50.663168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics[['loss','val_loss']].plot()\nplt.savefig('metrics_loss_plot.png')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:28:51.725567Z","iopub.execute_input":"2024-03-16T09:28:51.725902Z","iopub.status.idle":"2024-03-16T09:28:51.935162Z","shell.execute_reply.started":"2024-03-16T09:28:51.725878Z","shell.execute_reply":"2024-03-16T09:28:51.934158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_dir(\"results\")","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:28:52.710599Z","iopub.execute_input":"2024-03-16T09:28:52.711521Z","iopub.status.idle":"2024-03-16T09:28:52.715995Z","shell.execute_reply.started":"2024-03-16T09:28:52.711486Z","shell.execute_reply":"2024-03-16T09:28:52.715008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport cv2\ndef save_results(image, mask, y_pred, save_image_path):\n    mask = np.expand_dims(mask, axis=-1)\n    mask = np.concatenate([mask, mask, mask], axis=-1)\n\n    y_pred = np.expand_dims(y_pred, axis=-1)\n    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n    y_pred = y_pred * 255\n\n    line = np.ones((H, 10, 3)) * 255\n\n    cat_images = np.concatenate([image, line, mask, line, y_pred], axis=1)\n    cv2.imwrite(save_image_path, cat_images)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:29:19.467237Z","iopub.execute_input":"2024-03-16T09:29:19.467946Z","iopub.status.idle":"2024-03-16T09:29:19.473246Z","shell.execute_reply.started":"2024-03-16T09:29:19.467915Z","shell.execute_reply":"2024-03-16T09:29:19.472204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SCORE = []\nSCORE = []\nfor x, y in tqdm(zip(test_x, test_y), total=len(test_y)):\n    \"\"\" Extracting the name \"\"\"\n    name = x.split(\"/\")[-1]\n\n    \"\"\" Reading the image \"\"\"\n    image = cv2.imread(x, cv2.IMREAD_COLOR) ## [H, w, 3]\n    image = cv2.resize(image, (W, H))       ## [H, w, 3]\n    x = image/255.0                         ## [H, w, 3]\n    x = np.expand_dims(x, axis=0)           ## [1, H, w, 3]\n\n    \"\"\" Reading the mask \"\"\"\n    mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (W, H))\n\n    \"\"\" Prediction \"\"\"\n    y_pred = model.predict(x, verbose=0)[0]\n    y_pred = np.squeeze(y_pred, axis=-1)\n    y_pred = y_pred >= 0.5\n    y_pred = y_pred.astype(np.int32)\n\n    \"\"\" Saving the prediction \"\"\"\n    save_image_path = os.path.join(\"results\", name)\n    save_results(image, mask, y_pred, save_image_path)\n\n    \"\"\" Flatten the array \"\"\"\n    mask = mask/255.0\n    mask = (mask > 0.5).astype(np.int32).flatten()\n    y_pred = y_pred.flatten()\n\n    \"\"\" Calculating the metrics values \"\"\"\n    f1_value = f1_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    jac_value = jaccard_score(mask, y_pred, labels=[0, 1], average=\"binary\")\n    recall_value = recall_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    precision_value = precision_score(mask, y_pred, labels=[0, 1], average=\"binary\", zero_division=0)\n    SCORE.append([name, f1_value, jac_value, recall_value, precision_value])\n\n\"\"\" Metrics values \"\"\"\nscore = [s[1:]for s in SCORE]\nscore = np.mean(score, axis=0)\nprint(f\"F1: {score[0]:0.5f}\")\nprint(f\"Jaccard: {score[1]:0.5f}\")\nprint(f\"Recall: {score[2]:0.5f}\")\nprint(f\"Precision: {score[3]:0.5f}\")\n\ndf = pd.DataFrame(SCORE, columns=[\"Image\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\ndf.to_csv(\"files/score.csv\", index=None)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T09:42:23.603736Z","iopub.execute_input":"2024-03-16T09:42:23.604121Z","iopub.status.idle":"2024-03-16T09:42:23.962963Z","shell.execute_reply.started":"2024-03-16T09:42:23.604077Z","shell.execute_reply":"2024-03-16T09:42:23.961725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = pd.read_csv(\"/kaggle/working/files/score.csv\")\nscores.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir = \"/kaggle/working/results/\"\nimages = os.listdir(\"/kaggle/working/results\")[:5]\nimg1 = plt.imread(dir+images[0])\nplt.imsave('test_result1.png', img1, cmap='gray')\nplt.imshow(img1, cmap='gray')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = plt.imread(dir+images[1])\nplt.imsave('test_result2.png', img1, cmap='gray')\nplt.imshow(img1, cmap='gray')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = plt.imread(dir+images[2])\nplt.imsave('test_result3.png', img1, cmap='gray')\nplt.imshow(img1, cmap='gray')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_weights('/kaggle/input/final-model/model.h5.keras')","metadata":{"execution":{"iopub.status.busy":"2024-03-21T13:35:39.950298Z","iopub.execute_input":"2024-03-21T13:35:39.950991Z","iopub.status.idle":"2024-03-21T13:35:45.318754Z","shell.execute_reply.started":"2024-03-21T13:35:39.950956Z","shell.execute_reply":"2024-03-21T13:35:45.317733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# import cv2\n# import numpy as np\n# from tensorflow.keras.models import load_model\n\n\n# # Function to predict masks for images in a folder and save the masks in another folder\n# def predict_masks_and_apply(input_folder, output_folder):\n#     # Create the output folder if it doesn't exist\n#     if not os.path.exists(output_folder):\n#         os.makedirs(output_folder)\n    \n#     # Get a list of image filenames in the input folder\n#     image_filenames = os.listdir(input_folder)\n    \n#     # Iterate over each image\n#     for image_filename in image_filenames:\n#         # Read the image\n#         image_path = os.path.join(input_folder, image_filename)\n#         image = cv2.imread(image_path)\n        \n#         # Preprocess the image (you may need to adjust this based on your training preprocessing)\n#         image = cv2.resize(image, (224, 224))  # Resize the image to match the input size of your model\n#         image = image / 255.0  # Normalize pixel values\n        \n#         # Predict the mask\n#         mask = model.predict(np.expand_dims(image, axis=0))[0]\n        \n#         # Threshold the mask (assuming binary segmentation)\n#         mask[mask >= 0.5] = 255\n#         mask[mask < 0.5] = 0\n#         mask = mask.astype(np.uint8)\n        \n#         # Apply the mask to the image\n#         masked_image = cv2.bitwise_and(image, image, mask=mask)\n        \n#         # Save the masked image\n#         masked_image_filename = os.path.splitext(image_filename)[0] + '_masked.png'\n#         masked_image_path = os.path.join(output_folder, masked_image_filename)\n#         cv2.imwrite(masked_image_path, (masked_image * 255).astype(np.uint8))\n\n# # Apply masks to images in the \"benign\" folder and save them in the \"benign_masked\" folder\n# predict_masks_and_apply('/kaggle/input/dataset/dataset/BKM', '/kaggle/working/BKM_seg')\n\n# # Apply masks to images in the \"malignant\" folder and save them in the \"malignant_masked\" folder\n# predict_masks_and_apply('/kaggle/input/dataset/dataset/MSM', '/kaggle/working/MSM_seg')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T06:50:43.848576Z","iopub.execute_input":"2024-03-20T06:50:43.849245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count = 0\n# for file in os.listdir('/kaggle/working/MSM_concat'):\n#     count+=1\n# print(count)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:26:10.762849Z","iopub.execute_input":"2024-03-21T14:26:10.763680Z","iopub.status.idle":"2024-03-21T14:26:10.769674Z","shell.execute_reply.started":"2024-03-21T14:26:10.763648Z","shell.execute_reply":"2024-03-21T14:26:10.768746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n\n# # Function to create a zip archive of a folder\n# def create_zip(folder_path, zip_path):\n#     shutil.make_archive(zip_path, 'zip', folder_path)\n\n# # Paths to the folders containing the masked images\n# benign_masked_folder = '/kaggle/working/BKM_seg'\n# malignant_masked_folder = '/kaggle/working/MSM_seg'\n\n# # Create zip archives for the benign and malignant masked image folders\n# create_zip(benign_masked_folder, '/kaggle/working/BKM_seg.zip')\n# create_zip(malignant_masked_folder, '/kaggle/working/MSM_seg.zip')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T07:09:04.888496Z","iopub.execute_input":"2024-03-20T07:09:04.888854Z","iopub.status.idle":"2024-03-20T07:09:08.688396Z","shell.execute_reply.started":"2024-03-20T07:09:04.888824Z","shell.execute_reply":"2024-03-20T07:09:08.687403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dir = \"/kaggle/working/BKM_seg/\"\n# images = os.listdir(\"/kaggle/working/BKM_seg\")[:5]\n# print(images)\n# img1 = plt.imread(dir+images[2])\n# plt.imshow(img1, cmap='gray')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T07:28:48.093918Z","iopub.execute_input":"2024-03-20T07:28:48.094713Z","iopub.status.idle":"2024-03-20T07:28:48.369968Z","shell.execute_reply.started":"2024-03-20T07:28:48.094678Z","shell.execute_reply":"2024-03-20T07:28:48.369050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# import cv2\n# import numpy as np\n# from tensorflow.keras.models import load_model\n\n\n# # Function to predict masks for images in a folder and save the masks in another folder\n# def predict_masks_and_apply(input_folder, output_folder):\n#     # Create the output folder if it doesn't exist\n#     if not os.path.exists(output_folder):\n#         os.makedirs(output_folder)\n    \n#     # Get a list of image filenames in the input folder\n#     image_filenames = os.listdir(input_folder)\n    \n#     # Iterate over each image\n#     for image_filename in image_filenames:\n#         # Read the image\n#         image_path = os.path.join(input_folder, image_filename)\n#         image = cv2.imread(image_path)\n        \n#         # Preprocess the image (you may need to adjust this based on your training preprocessing)\n#         image = cv2.resize(image, (224, 224))  # Resize the image to match the input size of your model\n#         image = image / 255.0  # Normalize pixel values\n        \n#         # Predict the mask\n#         mask = model.predict(np.expand_dims(image, axis=0))[0]\n        \n#         # Threshold the mask (assuming binary segmentation)\n#         mask[mask >= 0.5] = 255\n#         mask[mask < 0.5] = 0\n#         mask = mask.astype(np.uint8)\n        \n#         # Apply the mask to the image\n#         if len(mask.shape) == 2:\n#             mask = np.stack([mask]*3, axis=-1)\n#         concatenated = np.concatenate([image, mask], axis=-1)\n    \n\n# #         # Visualize the original image\n# #         plt.figure(figsize=(10, 5))\n# #         plt.subplot(1, 2, 1)\n# #         plt.imshow(original_image)\n# #         plt.title('Original Image')\n\n# #         # Visualize the mask\n# #         plt.subplot(1, 2, 2)\n# #         plt.imshow(mask)\n# #         plt.title('Mask')\n\n# #         plt.show()\n\n# # Concatenate the image and mask along the channel dimension\n#         concatenated = np.concatenate([image, mask], axis=-1)\n#         concatenated_image_filename = os.path.splitext(image_filename)[0] + '_con.png'\n#         concatenated_image_path = os.path.join(output_folder, concatenated_image_filename)\n#         cv2.imwrite(concatenated_image_path, (concatenated* 255).astype(np.uint8))\n\n# # Apply masks to images in the \"benign\" folder and save them in the \"benign_masked\" folder\n# predict_masks_and_apply('/kaggle/input/dataset/dataset/BKM', '/kaggle/working/BKM_concat')\n\n# # Apply masks to images in the \"malignant\" folder and save them in the \"malignant_masked\" folder\n# predict_masks_and_apply('/kaggle/input/dataset/dataset/MSM', '/kaggle/working/MSM_concat')","metadata":{"execution":{"iopub.status.busy":"2024-03-21T13:58:23.114497Z","iopub.execute_input":"2024-03-21T13:58:23.115279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n\n# # Function to create a zip archive of a folder\n# def create_zip(folder_path, zip_path):\n#     shutil.make_archive(zip_path, 'zip', folder_path)\n\n# # Paths to the folders containing the masked images\n# benign_masked_folder = '/kaggle/working/BKM_concat'\n# malignant_masked_folder = '/kaggle/working/MSM_concat'\n\n# # Create zip archives for the benign and malignant masked image folders\n# create_zip(benign_masked_folder, '/kaggle/working/BKM_concat')\n# create_zip(malignant_masked_folder, '/kaggle/working/MSM_concat')","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:26:51.298916Z","iopub.execute_input":"2024-03-21T14:26:51.299773Z","iopub.status.idle":"2024-03-21T14:27:05.002624Z","shell.execute_reply.started":"2024-03-21T14:26:51.299743Z","shell.execute_reply":"2024-03-21T14:27:05.001843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}